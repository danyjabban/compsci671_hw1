{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 classifiers and metrics {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from gosdt import GOSDT\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  1  0 20  0]\n",
      " [18  1  1 33  0]\n",
      " [11  0  1 21  1]\n",
      " [31  0  0 18  1]\n",
      " [19  1  1  7  1]\n",
      " [21  1  0 10  0]\n",
      " [44  1  0 23  1]\n",
      " [15  1  1 16  0]\n",
      " [16  0  1 15  1]\n",
      " [17  1  0  6  0]]\n"
     ]
    }
   ],
   "source": [
    "dict3 = {'Age':[20,18,11,31,19,21,44,15,16,17], \n",
    "    'LikeRowing':[1,1,0,0,1,1,1,1,0,1], \n",
    "    'Experience':[0,1,1,0,1,0,0,1,1,0], \n",
    "    'Income':[20,33,21,18,7,10,23,16,15,6], \n",
    "    'Y':[0,0,1,1,1,0,1,0,1,0]}\n",
    "df = pd.DataFrame(dict3)\n",
    "data_matrix = df.to_numpy()\n",
    "print(data_matrix) \n",
    "# create data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation functions\n",
    "def boundry_confusion_matrix(ys_sort, i):\n",
    "    # arguments are sorted matrix of y's and function outputs, and index of threshold\n",
    "    tp = np.count_nonzero(ys_sort[:i, 1] == 1) # true positive\n",
    "    fp = np.count_nonzero(ys_sort[:i, 1] == 0) # false positive\n",
    "    fn = np.count_nonzero(ys_sort[i:, 1] == 1) # false negative\n",
    "    tn = np.count_nonzero(ys_sort[i:, 1] == 0) # true negative\n",
    "    conf_mat = np.array([[tp, fn], [fp, tn]]).T # confusion matrix\n",
    "    return conf_mat\n",
    "\n",
    "def misclassification_error(conf_mat, n):\n",
    "    # arguments are confusion matrix and number of observations\n",
    "    mc_error = (conf_mat[1,0] + conf_mat[0,1])/n\n",
    "    return mc_error\n",
    "\n",
    "def metrics(conf_mat):\n",
    "    # arguemnts are confusion matrix\n",
    "    if (conf_mat[0, 0] + conf_mat[0, 1]) == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = conf_mat[0,0]/(conf_mat[0, 0] + conf_mat[0, 1]) # calc precision\n",
    "    if (conf_mat[0, 0] + conf_mat[1, 0]) == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = conf_mat[0,0]/(conf_mat[0, 0] + conf_mat[1, 0]) # calc recall\n",
    "    if (precision + recall) == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2 * (precision * recall)/(precision + recall) # calc f1 score\n",
    "    return  precision, recall, f1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold evaluation function\n",
    "def evaluate_threshold(mat, func):\n",
    "    output_arr = np.array([])\n",
    "    for obs in mat: # iterate through each observation and get output from the function\n",
    "        output = [func(obs[:-1])] \n",
    "        output_arr = np.append(output_arr, output)\n",
    "    y = mat[:, -1]\n",
    "    ys = np.vstack([output_arr, y]).T # combine output array and y array\n",
    "    ys_sort = ys[ys[:, 0].argsort()] # sort by output values\n",
    "    ys_sort = np.flip(ys_sort, axis=0)\n",
    "    n = len(ys_sort) # num observations\n",
    "    threshold = np.array([]) # initialize threshold array\n",
    "    min_mc_error = 1 # initialize minimum classification error\n",
    "    for i in range(len(ys_sort) + 1): # iterrate through all thresholds\n",
    "        conf_mat = boundry_confusion_matrix(ys_sort, i)\n",
    "        new_mc_error = misclassification_error(conf_mat, n) \n",
    "        if new_mc_error < min_mc_error: # store error and threshold for new minimum misclassification error\n",
    "            threshold = [ys_sort[i-1: i+1, 0]] # threshold range exclusive\n",
    "            min_mc_error = new_mc_error\n",
    "            min_error_metrics = [metrics(conf_mat)]\n",
    "        elif new_mc_error == min_mc_error: # store error and threshold for new minimum misclassification error\n",
    "            threshold.append(ys_sort[i-1: i+1, 0]) # threshold range exclusive\n",
    "            min_error_metrics.append(metrics(conf_mat))\n",
    "    return min_mc_error, threshold, min_error_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g(x) for each observation\n",
      "g([20  1  0 20]) = -1.54\n",
      "g([18  1  1 33]) = 0.5640000000000001\n",
      "g([11  0  1 21]) = 3.1180000000000003\n",
      "g([31  0  0 18]) = 1.994\n",
      "g([19  1  1  7]) = 0.40600000000000025\n",
      "g([21  1  0 10]) = -1.5699999999999998\n",
      "g([44  1  0 23]) = -0.3159999999999999\n",
      "g([15  1  1 16]) = 0.2780000000000001\n",
      "g([16  0  1 15]) = 3.3200000000000003\n",
      "g([17  1  0  6]) = -1.8019999999999998\n"
     ]
    }
   ],
   "source": [
    "def g(x):\n",
    "    # create g(x) linear classifier\n",
    "    theta = np.array([0.05, -3, 2.1, 0.008])\n",
    "    theta_naught = 0.3\n",
    "    y_hat_i = np.dot(x, theta) + theta_naught\n",
    "    return y_hat_i\n",
    "\n",
    "print('g(x) for each observation')\n",
    "for obs in data_matrix:\n",
    "    output = [g(obs[:-1])]\n",
    "    print(f'g({obs[:-1]}) =',output[0])\n",
    "# g(x) for each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum misclassification error: 0.2\n",
      "threshold range: [array([1.994, 0.564]), array([0.406, 0.278]), array([-0.316, -1.54 ])]\n",
      "precision 1.0 recall 0.6 F1 0.7499999999999999\n",
      "precision 0.8 recall 0.8 F1 0.8000000000000002\n",
      "precision 0.7142857142857143 recall 1.0 F1 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "minimum_misclassification_thresholds = evaluate_threshold(data_matrix, g)\n",
    "print('minimum misclassification error:', minimum_misclassification_thresholds[0])\n",
    "print('threshold range:', minimum_misclassification_thresholds[1])\n",
    "for m in minimum_misclassification_thresholds[2]:\n",
    "    print('precision',m[0],'recall',m[1],'F1',m[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) for each observation\n",
      "f([20  1  0 20]) = -0.9121203692077172\n",
      "f([18  1  1 33]) = 0.510939234698401\n",
      "f([11  0  1 21]) = 0.9960923088427541\n",
      "f([31  0  0 18]) = 0.9636012140715537\n",
      "f([19  1  1  7]) = 0.3850710566999133\n",
      "f([21  1  0 10]) = -0.9170257613966083\n",
      "f([44  1  0 23]) = -0.3058856354111792\n",
      "f([15  1  1 16]) = 0.27105302652862084\n",
      "f([16  0  1 15]) = 0.9973893576929466\n",
      "f([17  1  0  6]) = -0.947012737861736\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    # tanh classifier\n",
    "    z = g(x)\n",
    "    e = math.e\n",
    "    output = (e**z - e**(-z))/(e**z + e**(-z))\n",
    "    return output\n",
    "\n",
    "print('f(x) for each observation')\n",
    "for obs in data_matrix:\n",
    "    output = [f(obs[:-1])]\n",
    "    print(f'f({obs[:-1]}) =',output[0])\n",
    "# f(x) for each point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum misclassification error: 0.2\n",
      "threshold range: [array([0.96360121, 0.51093923]), array([0.38507106, 0.27105303]), array([-0.30588564, -0.91212037])]\n",
      "precision 1.0 recall 0.6 F1 0.7499999999999999\n",
      "precision 0.8 recall 0.8 F1 0.8000000000000002\n",
      "precision 0.7142857142857143 recall 1.0 F1 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "minimum_misclassification_thresholds = evaluate_threshold(data_matrix, f)\n",
    "print('minimum misclassification error:', minimum_misclassification_thresholds[0])\n",
    "print('threshold range:', minimum_misclassification_thresholds[1])\n",
    "for m in minimum_misclassification_thresholds[2]:\n",
    "    print('precision',m[0],'recall',m[1],'F1',m[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def roc_points(conf_mat):\n",
    "    tpr = conf_mat[0,0]/(conf_mat[0, 0] + conf_mat[1, 0])\n",
    "    fpr = conf_mat[0,1]/(conf_mat[0, 1] + conf_mat[1, 1])\n",
    "    return np.array([[fpr, tpr]])\n",
    "\n",
    "def get_roc_points(mat, func):\n",
    "    output_arr = np.array([])\n",
    "    for obs in mat:\n",
    "        output = [func(obs[:-1])]\n",
    "        output_arr = np.append(output_arr, output)\n",
    "    y = mat[:, -1]\n",
    "    ys = np.vstack([output_arr, y]).T # combine output array and y array\n",
    "    ys_sort = ys[ys[:, 0].argsort()] # sort by output values\n",
    "    ys_sort = np.flip(ys_sort, axis=0)\n",
    "    n = len(ys_sort) # num observations\n",
    "    roc_mat = np.empty((0,2), int)\n",
    "    for i in range(len(ys_sort) + 1): # iterrate through all thresholds\n",
    "        conf_mat = boundry_confusion_matrix(ys_sort, i)\n",
    "        points = roc_points(conf_mat)\n",
    "        roc_mat = np.append(roc_mat, points, axis=0)\n",
    "    roc_df = pd.DataFrame(roc_mat, columns = ['fpr', 'tpr'])\n",
    "    plt.plot('fpr', 'tpr', data=roc_df, linestyle='-') \n",
    "    plt.plot([0,.2,.4], [.6,.8, 1],'o') \n",
    "    plt.legend(['roc curve', 'minimum misclassification points'])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "get_roc_points(data_matrix, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Classification with KNN and Decision Trees {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to perform hyperparameter tuning cross validation\n",
    "\n",
    "def k_fold_cv(data, params, clf, target_col_name, gosdt=False):\n",
    "    # take whole training data and shuffle rows\n",
    "    data = data.sample(frac=1)\n",
    "    # split into 10 folds\n",
    "    num_rows = data.shape[0]\n",
    "    fold_size = math.ceil(num_rows/10)\n",
    "    # loop through 10 folds using 9 as training set\n",
    "    f1_df = pd.DataFrame()\n",
    "    for i in range(0, num_rows, fold_size):\n",
    "        val, train = split_train_val(data, i, fold_size, num_rows)\n",
    "        val_X, val_y = preprocess_data(val, target_col_name)\n",
    "        train_X, train_y = preprocess_data(train, target_col_name)\n",
    "\n",
    "       \n",
    "        # iterrate through all combinations of hyperperameters\n",
    "        f1_dict = {} # dictionary of f1 scores for each hyperparam pair\n",
    "        for param_j in params[list(params.keys())[0]]:\n",
    "            for param_k in params[list(params.keys())[1]]:\n",
    "                dp = {list(params.keys())[0]: param_j, list(params.keys())[1]: param_k}\n",
    "                if gosdt:\n",
    "                    clf_model = clf(dp)\n",
    "                else:\n",
    "                    clf_model = clf(**dp) # create instance of the model with given hyperparameters\n",
    "                clf_model.fit(train_X, train_y) # fit with training data\n",
    "                y_pred = clf_model.predict(val_X) # get predicted y vals\n",
    "                val_y['y_pred'] = y_pred # create dataframe with true y's and y_hats\n",
    "                conf_mat = confusion_matrix(val_y, target_col_name)\n",
    "                f1_score = metrics(conf_mat)[0]\n",
    "                param_comb = 'param_j:' + str(param_j) + ',param_k:' + str(param_k)\n",
    "                f1_dict[param_comb] = [f1_score]\n",
    "        f1_df = pd.concat([f1_df, pd.DataFrame(f1_dict)]) # add new row of f1 scores\n",
    "    f1_df.reset_index(inplace=True, drop=True)\n",
    "    return f1_df\n",
    "\n",
    "def split_train_val(data, i, fold_size, num_rows):\n",
    "    # split training data into train and validation groups\n",
    "    eval = data.iloc[i:i+fold_size] # evaluation fold\n",
    "    train1 = data.iloc[0:i] # train set 1\n",
    "    train2 = data.iloc[i+fold_size: num_rows] # train set 2\n",
    "    train = pd.concat([train1, train2]) # combine train sets\n",
    "    return eval, train\n",
    "\n",
    "\n",
    "def preprocess_data(data, target_name):\n",
    "    feature_names = data.columns.to_list() # get feature cols\n",
    "    feature_names.remove(target_name) \n",
    "\n",
    "    data_X = data[feature_names] # feature df\n",
    "    data_y = data[[target_name]] # target df\n",
    "    data_X = pd.get_dummies(data_X, drop_first=True) # one hot encoding\n",
    "    data_X = data_X.reset_index(drop=True)\n",
    "    data_y = data_y.reset_index(drop=True)\n",
    "    return data_X, data_y\n",
    "\n",
    "\n",
    "def confusion_matrix(df, target_col_name):\n",
    "    '''\n",
    "    create a confusion matrix from the given df of y's and y_hat's\n",
    "    '''\n",
    "    tp = df.loc[(df[target_col_name] == 1) & (df['y_pred'] == 1)].shape[0]\n",
    "    fn = df.loc[(df[target_col_name] == 1) & (df['y_pred'] == 0)].shape[0]\n",
    "    fp = df.loc[(df[target_col_name] == 0) & (df['y_pred'] == 1)].shape[0]\n",
    "    tn = df.loc[(df[target_col_name] == 0) & (df['y_pred'] == 0)].shape[0]\n",
    "    conf_mat = np.array([[tp, fn], [fp, tn]]) # confusion matrix\n",
    "    return conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKlearn decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"carseats_train.csv\" # training data file\n",
    "df = pd.read_csv(train_file)\n",
    "target_col_name = 'Sales'\n",
    "params_dict = {'criterion':[\"gini\", \"entropy\"], 'max_depth':[2,3]}\n",
    "cv_scores = k_fold_cv(df, params_dict, dtc, target_col_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 scores for each of the hyperparameter pairs\n",
      "Note: param_j is criterion and param_k is max_depth\n",
      "param_j:gini,param_k:2       0.458497\n",
      "param_j:gini,param_k:3       0.498864\n",
      "param_j:entropy,param_k:2    0.425164\n",
      "param_j:entropy,param_k:3    0.511288\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Average F1 scores for each of the hyperparameter pairs')\n",
    "print('Note: param_j is criterion and param_k is max_depth')\n",
    "cv_mean = cv_scores.mean()\n",
    "print(cv_mean)\n",
    "# param_j is criterion and param_k is max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sklearn decision trees the best performing hyperparameter combination was criteria:entropy and max_depth:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOSDT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_file = \"carseats_train.csv\" # training data file\n",
    "df = pd.read_csv(train_file)\n",
    "target_col_name = 'Sales'\n",
    "config = {\n",
    "        \"regularization\": [.05,0.001],\n",
    "        \"depth_budget\": [2, 3]\n",
    "    }\n",
    "cv_scores = k_fold_cv(df, config, GOSDT, target_col_name, gosdt = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 scores for each of the hyperparameter pairs\n",
      "Note: param_j is regularization and param_k is depth_budget\n",
      "param_j:0.05,param_k:2     0.390638\n",
      "param_j:0.05,param_k:3     0.390638\n",
      "param_j:0.001,param_k:2    0.390638\n",
      "param_j:0.001,param_k:3    0.556850\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Average F1 scores for each of the hyperparameter pairs')\n",
    "print('Note: param_j is regularization and param_k is depth_budget')\n",
    "cv_mean = cv_scores.mean()\n",
    "print(cv_mean)\n",
    "# param_j is regularization and param_k is depth_budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GOSDT the best performing hyperparameter combination was regularization:0.001 and depth_budget:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "### knn class\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, dist_metric, k):\n",
    "        if dist_metric == \"euclidean\":\n",
    "            self.dist_metric = self.euclidean_distance\n",
    "        elif dist_metric == 'manhattan':\n",
    "            self.dist_metric = self.manhattan_distance\n",
    "        self.k = k\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.train_data_X = X \n",
    "        self.train_data_y = y\n",
    "\n",
    "    \n",
    "    def predict(self, test_data_X):\n",
    "        '''\n",
    "        predict the y labels for the dataframe test_data_X \n",
    "        '''\n",
    "        # list of y_hats\n",
    "        y_hat_list = []\n",
    "        # iterrate through each test row\n",
    "        for test_i, test_row in test_data_X.iterrows():\n",
    "            self.closest_points_dist = [] # list of the k smallest distances for a given test_row\n",
    "            self.closest_points_ys = [] # list of corresponding y's associated with the train row with the smallest distances\n",
    "            for train_i, train_row in self.train_data_X.iterrows():\n",
    "                # get distance\n",
    "                new_dist = self.dist_metric(test_row.values.flatten().tolist(), train_row.values.flatten().tolist())\n",
    "                # check largest dist and if new dist is less then replace it and its corresponding y\n",
    "                self.check_largest_dist(new_dist, train_i)\n",
    "            y_mean = sum(self.closest_points_ys)/len(self.closest_points_ys)\n",
    "            # determine the label for y_hat\n",
    "            if y_mean >= .5:\n",
    "                y_hat_list.append(1)\n",
    "            else:\n",
    "                y_hat_list.append(0)\n",
    "        return y_hat_list\n",
    "    \n",
    "    \n",
    "    def check_largest_dist(self, new_dist, train_index):\n",
    "        '''\n",
    "        check to see if the distance between the current training point and the test point\n",
    "        is smaller than the largest distance in the list of k smallest distances\n",
    "        '''\n",
    "        if len(self.closest_points_dist) > 0:\n",
    "            max_in_list = max(self.closest_points_dist) # get largest value in list\n",
    "        # if list doesnt have k elements already just add new distance and train_y to respective lists\n",
    "        if len(self.closest_points_dist) < self.k: \n",
    "            self.closest_points_dist.append(new_dist)\n",
    "            self.closest_points_ys.append(self.train_data_y.iloc[train_index].values[0])\n",
    "        # else check if the newest distance is less than the largest distance in the list of k elements\n",
    "        # if it is switch them out and switch out their respective y's\n",
    "        elif new_dist < max_in_list:\n",
    "            index_of_max = self.closest_points_dist.index(max_in_list)\n",
    "            self.closest_points_dist.pop(index_of_max) # drop the old largest distance from list\n",
    "            self.closest_points_dist.append(new_dist) # add the new distance to the list\n",
    "            self.closest_points_ys.pop(index_of_max) # drop the y value corresponding to the point that was just dropped\n",
    "            self.closest_points_ys.append(self.train_data_y.iloc[train_index].values[0]) # add the y of the new distance\n",
    "        \n",
    "\n",
    "    def euclidean_distance(self, test_row, train_row): \n",
    "        # train and test are lists\n",
    "        dist = 0\n",
    "        for i in range(len(train_row)):\n",
    "            dist = dist + (train_row[i] - test_row[i])**2\n",
    "        dist = (dist)**(1/2)\n",
    "        return dist\n",
    "\n",
    "\n",
    "    def manhattan_distance(self, test_row, train_row): \n",
    "        # train and test are lists\n",
    "        dist = 0\n",
    "        for i in range(len(train_row)):\n",
    "            dist = dist + abs(train_row[i] - test_row[i])\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"carseats_train.csv\" # training data file\n",
    "df = pd.read_csv(train_file)\n",
    "target_col_name = 'Sales'\n",
    "params_dict = {'dist_metric':[\"euclidean\", \"manhattan\"], 'k':[1,3]}\n",
    "cv_scores = k_fold_cv(df, params_dict, KNN, target_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 scores for each of the hyperparameter pairs\n",
      "Note: param_j is distance_metric and param_k is k\n",
      "param_j:euclidean,param_k:1    0.420649\n",
      "param_j:euclidean,param_k:3    0.318225\n",
      "param_j:manhattan,param_k:1    0.464892\n",
      "param_j:manhattan,param_k:3    0.359026\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Average F1 scores for each of the hyperparameter pairs')\n",
    "print('Note: param_j is distance_metric and param_k is k')\n",
    "cv_mean = cv_scores.mean()\n",
    "print(cv_mean)\n",
    "# param_j is distance metric and parak_k is k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN the best performing hyperparameter combination was dist_metric:manhattan and k:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4) {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gosdt reported successful execution\n",
      "training completed. 0.502/0.007/0.515 (user, system, wall), mem=243524 MB\n",
      "bounds: [0.220312..0.220312] (0.000000) loss=0.216312, iterations=1115\n",
      "gosdt_model f1 score: 0.4576271186440678\n",
      "sktree_model f1 score: 0.7288135593220338\n",
      "knn_model f1 score: 0.5254237288135594\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Fit the three algorithms with tuned hyperparameters on the full trainng data \n",
    "Then Get the F1 score using the test data\n",
    "'''\n",
    "\n",
    "\n",
    "def test_model(model, train_X, train_y, test_X, test_y):\n",
    "    model.fit(train_X, train_y) # fit with training data\n",
    "    y_pred = model.predict(test_X) # get predicted y vals\n",
    "    test_y['y_pred'] = y_pred # create dataframe with true y's and y_hats\n",
    "    conf_mat = confusion_matrix(test_y, target_col_name)\n",
    "    f1_score = metrics(conf_mat)[0]\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "train_file = \"carseats_train.csv\" # training data file\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_file = \"carseats_test.csv\" # testing data file\n",
    "test_df = pd.read_csv(test_file)\n",
    "target_col_name = 'Sales'\n",
    "train_X, train_y = preprocess_data(train_df, target_col_name)\n",
    "test_X, test_y = preprocess_data(test_df, target_col_name)\n",
    "\n",
    "\n",
    "\n",
    "# configure gosdt classifier\n",
    "params = {'regularization':0.001, 'depth_budget':3}\n",
    "gosdt_model = GOSDT(params)\n",
    "f1 = test_model(gosdt_model, train_X, train_y, test_X, test_y)\n",
    "print(\"gosdt_model f1 score:\", f1)\n",
    "\n",
    "# configure sklearn decision tree classifier\n",
    "params = {'criterion':\"entropy\", 'max_depth':3}\n",
    "sktree_model = dtc(**params)\n",
    "f1 = test_model(sktree_model, train_X, train_y, test_X, test_y)\n",
    "print(\"sktree_model f1 score:\", f1)\n",
    "\n",
    "# configure knn classifier\n",
    "params = {'dist_metric':\"manhattan\", 'k':1}\n",
    "knn_model = KNN(**params)\n",
    "f1 = test_model(knn_model, train_X, train_y, test_X, test_y)\n",
    "print(\"knn_model f1 score:\", f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the f1 score, the SKLearn Decision Tree Classifier CART model with parameters Criterion = entropy and max_depth = 3 performed the best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88caf069edf20051aa562fca5c59ddb764012baca65fbe1d1bef7ace59050dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
